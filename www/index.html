<html>
<head>
<title>Build Interceptor</title>
</head>
<body bgcolor=white>

<center><h1>Build Interceptor</h1></center>

<p><b>Maintainer:</b> Daniel S. Wilkerson
<br><b>Developers:</b> Karl Chen

<p><b>Build Interceptor</b> captures the .i files of any project while
it is built from source using the gcc toolchain.

<p>Anyone who has tried this on a large scale will find out that it is
non-trivial to build a project from source and obtain the .i files
generated during the build process.  I give step-by-step instructions
on how to use the provided scripts to do this without *any*
modification to the build process of the project you are trying to
capture.

<p>These scripts were used to capture the build process of 92.5% of
the projects in the Red Hat Linux 7.3 distribution, resulting in the
RH7.3.i dataset below.  Build Interceptor is released under the BSD
license.

<ul>
<li><a
href=http://cich.cs.berkeley.edu/dsw/public_html/build_interceptor-2004.11.19.tar.gz>build_interceptor-2004.11.19.tar.gz</a> &nbsp; md5:
<code>
a4299ddab5ad0e3c7aecc53a5e750101
</code>
<b>NOTE:</b> Build interceptor has been improved substantially since
this release, but I haven't released another version yet as we are
still testing it.  Feel free to just get the current Subversion
repository version as a guest user.
</ul>

<hr>

<center><h1>RH7.3.i</h1></center>

<p><b>RH7.3.i</b> is the .i files generated while Red Hat Linux 7.3
was built from source, as recorded by Build Interceptor.  I also
include the source RPMs for Red Hat Linux 7.3; the ISOs are <a
href=ftp://mirrors.hpcf.upr.edu/pub/Mirrors/redhat/ftp.redhat.com/linux/7.3/en/iso/i386/>here</a>.

<p><font color=red><b>NOTE: I am considering removing RH7.3.i from the
web.  If you think this is a bad idea, let me know.</b></font> Build
interceptor is now hosted on tigris.org and they are not willing to
host such large files as this on their site.  If you are actually
using RH7.3.i, please let me know.

<p><b>NOTE:</b> In my naivete, it looks like I omitted capturing the
.i files for dynamically linked libraries; that is, the .i files
published for an executable will not include the .i files for the
dynamically linked libraries that it would be linked with at run-time.
I will confirm this and post the definitive answer.  This will be
fixed in future versions of Build Interceptor.

<p>Read the <a
href=http://cich.cs.berkeley.edu/dsw/public_html/Readme_RH7.3.i-2004.11.19.txt>RH7.3.i
Readme</a>.

<p>The tarball is 3.6 Gig, so I used 'split' to break it apart into
four chunks each less than 1 Gig.  There is no need to ever
materialize it as one file; just download each file and do this.

<p>
<code>
cat RH7.3.i-VERSION.tar.gz.* | gunzip | tar xv -f -
</code>

<ul>
<li><a href=http://cich.cs.berkeley.edu/dsw/public_html/RH7.3.i-2004.11.19.tar.gz.aa>RH7.3.i-2004.11.19.tar.gz.aa</a> 
&nbsp; md5: <code>546c269999d54ad8e3581963912a5c61</code>
<li><a href=http://cich.cs.berkeley.edu/dsw/public_html/RH7.3.i-2004.11.19.tar.gz.ab>RH7.3.i-2004.11.19.tar.gz.ab</a>
&nbsp; md5: <code>e9c4c8880df6576360cfcda1d4cb9833</code>
<li><a href=http://cich.cs.berkeley.edu/dsw/public_html/RH7.3.i-2004.11.19.tar.gz.ac>RH7.3.i-2004.11.19.tar.gz.ac</a>
&nbsp; md5: <code>f8448f06c01c5a3df62a7bd5b7cade89</code>
<li><a href=http://cich.cs.berkeley.edu/dsw/public_html/RH7.3.i-2004.11.19.tar.gz.ad>RH7.3.i-2004.11.19.tar.gz.ad</a>
&nbsp; md5: <code>b83d101805a5a6b5570902ba7f708b5a</code>
</ul>

<hr>


<center>

<h1>Build Interceptor Readme</h1>
<a href="http://build-interceptor.tigris.org/">http://build-interceptor.tigris.org/</a>
<p><b>Daniel S. Wilkerson</b>

</center>

<h2>Introduction</h2>

<p>Welcome!  Build Interceptor is a collection of scripts for recording
the .i files generated during a build of C or C++ programs with the
gcc toolchain.  No modification to the original build process is
necessary.

<h3>Limitations</h3>

<p>The method described here requires that you be root on your box so you
can replace the system cc1 and cc1plus programs, among others; this is
done so that the build process you are intercepting does not have to
be changed at all.  You can probably also get it to work by setting
environment variables such as GCC_EXEC_PREFIX.  I could not figure out
how to change the compiler proper (cc1) from gcc spec files.

<p>The previous version of this tool would not work with the gcc 3 series
as the preprocessor and compiler had been integrated; however since
then by looking through the source code I discovered the seemingly
undocumented flag "--no-integrated-cpp" which solves this problem.

<p>Compilers other than gcc are not supported.  Gcc 3.4.0 works but
versions earlier than this seem to have different spec file
conventions; gcc 3.2.3 seems to not work.

<h3>Background</h3>

<p>When gcc/g++ compiles, it pre-processes .c or .cc files to .i or .ii
files (respectively), compiles .i or .ii files to .s files, assembles
.s files to .o files, and links .o files to executables.  It
traditionally does all these stages with separate programs (new
versions of gcc complicate this by integrating preprocessing and
compilation), in particular the compiler-proper program being called
cc1 or cc1plus for C or C++ (respectively).

<h3>Basics of how the build interception works</h3>

<p>The cc1_interceptor.pl script captures the .i and .ii files generated
by the gcc compiler tool chain by replacing and imitating cc1.  It

   1) copies the pre-processed input, the .i file, to a new file,

   2) runs the real cc1 passing in the copy,

   3) puts the fully-qualified filename of the copy into a string in
      the section ".note.cc1_interceptor" in the assembly output.

<p>This name flows to the .o and then to the executable (the linker will
concatenate multiple occurrences of this section) where it can later
be retrieved using objdump; This is easier to do if you use Ben
Liblit's extract-section script which he ships as part of "The
Cooperative Bug Isolation Project" and which I include in this
project; see below for details.

<p>The build interceptor process works by first moving away the system
executables (using the Intercept.mk makefile, as root) and replacing
them with softlinks to the interception scripts provided.

<h2>Licensing</h2>

<p>All files in this directory tree and its subtrees are distributed
under the license in License.txt; please see that file for copyright
and terms of use.

<h2>Design</h2>

<p>Our design builds on the experience of the MOPS project and
Cooperative Bug Isolation Project (CBI), which I talk more about in
the Acknowledgments section below.

<p>There are other ways one might attempt build process interception.
This particular design has been chosen to avoid some problems that are
not at all obvious if you have not tried this before.  The salient
lesson of those other projects is that build-processes are very
complex and interception is hard to do without breaking them; testing
is very difficult because if something fails it is hard to know how
what went wrong or even if something went wrong.  The number one
concern of the design is therefore to keep things as simple and
non-intrusive as possible.

<h4>Staged interception</h4>

<p>We do not pipeline the build interception with any further analysis
of the generated .i files.  That is we just save the generated .i
files, we don't run an analysis right then; the MOPS project (below)
did attempt to analyze .i files as they were generated.  When a build
would fail, they assumed that their analysis had failed.  When we
later separated the interception from the analysis, we found that in
fact the interception was often failing but this was going undetected.

<p>Another reason to not separate them is that if your analysis does
fail, you often want to re-run it multiple times as you gradually
minimize the input, such as while using the delta file minimizer tool
(http://www.cs.berkeley.edu/~dsw/).  This is only possible if you have
already materialized the .i file somewhere separately.

<p>Basically a complex process should be staged if at all possible to
reduce complexity.

<h4>Metadata lives in data</h4>

<p>We do not attempt to keep metadata on build-process-generated files
anywhere outside the files themselves.  Early versions of the MOPS
projects attempted to put derived data from a .i file into another
file and then somehow maintain an association between the two.  This
was found to be impossible due to build processes moving files around
etc.

<p>All metadata for a file is inserted into the file in one way or
another, depending on the current language the file is in: at the
compile stage, it is inserted into the generated assembly (a trick
novel to build_interceptor) and at the link stage it is inserted into
the .o file using objcopy (a trick from MOPS and also CBI as well I
think).

<h4>Avoid long-range communication outside of data</h4>

<p>We do not attempt out-of-band communication between the various
sub-processes of gcc, which differs from both MOPS and CBI.  MOPS for
example attempts to capture the preprocessing stage, analyze it, and
then insert the results in after the linking stage.  Getting rid of
this long-range dependency between stages greatly simplifies things.

<p><b>NOTE:</b> I think this may no longer be true with the new
strategy of embedding .i files directly into ELF files.

<h4>Avoid parsing complex command-lines</h4>

<p>Similarly we do not attempt to parse the command-line arguments
of gcc.  Again, the simplification of the process is huge; we only
parse arguments of simple tools such as cc1 and collect2; their
command-lines are much simpler as another tool uses them, not a human.

<p>Something you might be tempted to do along these lines is to remove
-O* flags from the compile stage to speed things up, since perhaps you
are only interested in the .i files and not in actually using the
resulting executables.  Removing -O* from the compile stage alone will
not work, as if it has been passed to the preprocessing stage the
compile stage will fail to compile it due to various things having
been inlined.  I suppose it would work to remove it from all stages,
probably using the gcc spec file mechanism, but I don't consider it
worth the complexity and possibility of failure.

<h2>Goals and amount of interception</h2>

<p>What tools must be intercepted during the build process depends on
what your goal is.  You can turn off the interception of tools by
removing them from intercept.progs after it is built.

<h4>File-by-file</h4>

<p>For a file-by-file analysis of source code, you simply need the source
files after pre-processing.  It is sufficient to just intercept
cc1/cc1plus and (after running reorg_build.pl) look at the resulting
.i files.

<p>Note that even if you do not intercept cpp/cpp0/tradcpp0/gcc -E, the
gcc spec file will tell gcc to not pass -P which means there should
always be line directives in the .i file.  So if your analysis finds
an error, it can always map it back to the original source line.

<h4>Whole-program</h4>

<p>For a whole-program analysis of all the source in the package, you
need to know for each executable which .i files went into it.  Each
such executable (and any other files produced by the linker) will
result in a .ld file which lists all the .i files that went into it
that were compiled during the build.

<p>For a really whole-program analysis that also looks at libraries, or
if you wanted to modify the .i files, recompile, and re-link, you need
to know *all* the .o files that went into an executable.  For this you
will need to also intercept collect2, which is implemented; however
the script reorg.pl would also have to be extended to extract the
linker --trace output, but this is straightforward.

<p>You would want to intercept 'as' to make a mapping between .s files
output by cc1/cc1plus and .o files linked together by the linker as
well as the command-line.  It would probably be best to insert the
metadata after assembly using objcopy, just as with collect2.

<h4>Source-to-source</h4>

<p>If you wanted to do a source-to-source transformation on the
original source you would need the preprocessing command line as well,
and so would have to intercept cpp/cpp0/tradcpp0/gcc -E; probably you
would insert the metadata into the file as the initializer of a global
string variable with an unusual name.

<p>"Replaying" a build process from the interception record is probably
trickier than one might at first imagine: build processes sometimes do
strange things such as move files around.  You would have to intercept
mv and perhaps rm etc.  I have not done this but it is not hard given
the infrastructure.  One thing you will likely want is for the build
process to be deterministic, so the make interceptor removes -j from
the command line; try out the TestMake.mk makefile with and without
it.

<h4>Miscellaneous difficulties with gcc layering</h4>

<p>You might have to experiment to figure out exactly what which layer to
intercept.  I am using gcc 3.4.0 and it seems that neither cpp nor gcc
-E call each other nor a program called cpp0, which seems to not exist
anymore; however perhaps gcc 2.95.3 does.  Similarly, ld does not call
collect2, though the gcc source code suggests in a comment that they
are interchangeable; why do the both exist?  To assist in this
experimentation, each interceptor script prints at the start its 1)
name, 2) parent process id, 3) own process id and 4) arguments all to
standard error (this may have been commented out, just uncomment).

<h2>Using the scripts</h2>

<p>These scripts were originally written to capture the .i files
generated when building the Red Hat Linux 7.3 distribution from source
as a test for the Elsa/Oink C/C++ front end and analysis tools.  The
first release of build_interceptor used as an example of how to use
these scripts the process of building Red hat 7.3 from source and
capturing the .i files.  Those instructions are still available in
RedHat7.3.Readme.

<pre>
# One-time initial setup of build_interceptor.
cd; cd build_interceptor

# The makefile will build interceptor.specs for you according to your
# auto-detected gcc version, however you might need to hack on it
# anyway.  For example on gcc 3.4 one line has to look like this:
#   %&lt;P %(cpp_options_old0)
# whereas on earlier versions of gcc, it has to look like this:
%   %{&lt;P} %(cpp_options_old0)

# Build the softlinks and the intercept.progs.
make
# Now check that the files you want to intercept are generated in
# intercept.progs.  You can change this file if you need to, but only
# do it while build interception is off!  Otherwise you can get into
# an inconsistent state.

# Make a place to put the .i files.
cd
mkdir ball_preproc
ln -s ball_preproc preproc

# Move your system gcc to gcc_orig and link gcc to gcc_interceptor.pl.
# NOTE: it is important to be in $HOME/build_interceptor so that `pwd`
# works below; $HOME will become '/root' once you su.
cd; cd build_interceptor
su
make -f Intercept.mk on
# You could exit the root shell now, but I find it easier to instead
# just leave one shell open as root for turning interception on and
# off and do user things in another shell.
exit # the root shell

# At any time you can check the interception state.
make -f Intercept.mk

# Build your project.

# If you mess up and need to start over again, just do this.
rm -rf preproc/*
# If you want to build two different projects and capture both, just
# move the link.
mkdir ball_preproc2
ln -s ball_preproc2 preproc

# Before compiling anything else with gcc:
# 1 - Make the data read-only.
cd
chmod -R a-w ball_preproc
# 2 - Point the preprocessor capture at another file
mkdir preproc_junk
ln -s preproc_junk preproc

# When you are done, put gcc back where it was.
cd; cd build_interceptor
su
make -f Intercept.mk off
exit # the root shell

# Run reorg on the output.  The script expects to find 1) a directory
# for each project built in $HOME/build, and 2) the .i files generated
# by interception in $HOME/preproc.  It will store the reorganized .i
# and .ld files in $HOME/ball.
cd; cd build_interceptor
./reorg_build.pl

</pre>

<h3>Files</h3>

<p>To simplify things, the scripts make some assumptions about what files
and directories are where.  I list them here; all are assumed to be
under $HOME.<ul>

<li>ball_preproc: Where the captured preprocessing output of
cc1_interceptor.pl goes.

<li>preproc: Link to ball_preproc.

<li>ball_build: The root of the tree where the source RPMs get built.

<li>ball: The directory that results from reorganizing the captured .i
files according to the .note.cc1_im sections left behind in the
executables and .o files.

<li>ball_fail_c.files and ball_fail_cc.files: The files where gcc_all.pl
puts the list of .i files that fail to build with gcc after being
captured by the build process.

</ul>

<h2>FAQ</h2>

<pre>
Date: Fri, 28 Jan 2005 15:17:30 -0800
Scott McPeak wrote:

> Do you know there is a form of -j that takes no arguments?

Thanks for pointing this out.  For now I will just turn it off.

> I bet it's just whether the next argument is entirely numeric, which
> would at least be a fairly simple rule, but still stupid.

These are the kind of situations that you have to be very careful to
not get yourself into with the primary tools, such as gcc.  Hao was
attempting to parse gcc's arguments, and these sorts of things killed
his design.

> Also, why do you transform /usr/bin/gmake into /usr/bin/make?

I do this for gcc_interceptor.pl as well.  Think about what happens
when you call make as /usr/bin/gmake.  This follows a softlink (which
is always there) to /usr/bin/make, which has been replaced (by build
interception) with a softlink to my script
/home/dsw/build_interceptor/make_interceptor.pl (say), which is what
runs.  Now, that script has to find the real make, which it does as
${0}_orig.  In this case, that is /usr/bin/gmake_orig, which doesn't
exist.  However /usr/bin/make_orig does exist, and my going through
the mapping first, you find it.  If you can come up with another
scheme that works, let me know, but I tried a few others and none of
them worked.
</pre>

<h2>Acknowledgments</h2>

<p>I used code and ideas for build-process interception from two
different previous projects that dealt with this same problem. <ul>

<li>The <a href="http://www.cs.berkeley.edu/~liblit/sampler/">"The
Cooperative Bug Isolation Project"</a> by Ben Liblit

<li>The <a href="http://sourceforge.net/projects/mopscode">MOPS</a>
project by Hao Chen where he and Geoff Morrison in particular worked
on the build-process interception aspect.

</ul>

<p>The idea of inserting metadata into an unused section in ELF .o files
was borrowed from Ben and Hao.  I extended it back to the assembly
stage.

<p>Ben Liblit, Hao Chen, John Kodumal, and Simon Goldsmith contributed to
the discussions leading to these scripts.  Thanks especially to Simon
Goldsmith for proof-reading this Readme [I of course take
responsibility for any remaining mistakes].

<p>Thanks to Andy Begel for his in-depth explanation of dynamic linking
under various circumstances and operating systems.

</body>
</html>
